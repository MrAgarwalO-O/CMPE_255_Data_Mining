{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "NXLP5h04RZfY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_CSV = '/kaggle/input/ucf101-action-recognition/train.csv'\n",
        "VAL_CSV = '/kaggle/input/ucf101-action-recognition/val.csv'\n",
        "TEST_CSV = '/kaggle/input/ucf101-action-recognition/test.csv'\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "val_df = pd.read_csv(VAL_CSV)\n",
        "test_df = pd.read_csv(TEST_CSV)"
      ],
      "metadata": {
        "id": "AmgeptGHQ3Mo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "LtD3DeWbPvF0",
        "outputId": "4b0d85d6-07e3-4bf9-9b31-1ab82e1e39d8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-57ee101dab0e>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Extract features from the first video file as an example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_eye_makeup_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_eye_makeup_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_video_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def extract_video_features(video_path, num_frames=5):\n",
        "    # Initialize video capture object\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get video properties\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Initialize variables to store features\n",
        "    color_histograms = []\n",
        "    edge_histograms = []\n",
        "\n",
        "    # Extract frames from the video\n",
        "    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
        "    for i in frame_indices:\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "            # Convert frame to grayscale\n",
        "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Compute color histogram for each channel (RGB)\n",
        "            color_hist = []\n",
        "            for j in range(3):\n",
        "                hist = cv2.calcHist([frame], [j], None, [256], [0, 256])\n",
        "                color_hist.append(hist.flatten())\n",
        "            color_histograms.append(np.concatenate(color_hist))\n",
        "\n",
        "            # Compute edge histogram\n",
        "            edges = cv2.Canny(gray_frame, 100, 200)\n",
        "            edge_hist = cv2.calcHist([edges], [0], None, [256], [0, 256])\n",
        "            edge_histograms.append(edge_hist.flatten())\n",
        "\n",
        "    # Release video capture object\n",
        "    cap.release()\n",
        "\n",
        "    # Create feature dictionary\n",
        "    features = {\n",
        "        'color_histograms': np.array(color_histograms).mean(axis=0),\n",
        "        'edge_histograms': np.array(edge_histograms).mean(axis=0),\n",
        "    }\n",
        "\n",
        "    return features\n",
        "\n",
        "# Extract features from the first video file as an example\n",
        "video_path = os.path.join(apply_eye_makeup_folder_path, apply_eye_makeup_files[0])\n",
        "features = extract_video_features(video_path)\n",
        "features\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables to store features for all videos\n",
        "all_color_histograms = []\n",
        "all_edge_histograms = []\n",
        "\n",
        "# Extract features from all video files\n",
        "for video_file in apply_eye_makeup_files:\n",
        "    video_path = os.path.join(apply_eye_makeup_folder_path, video_file)\n",
        "    features = extract_video_features(video_path)\n",
        "    all_color_histograms.append(features['color_histograms'])\n",
        "    all_edge_histograms.append(features['edge_histograms'])\n",
        "\n",
        "# Convert features to NumPy arrays\n",
        "all_color_histograms = np.array(all_color_histograms)\n",
        "all_edge_histograms = np.array(all_edge_histograms)\n",
        "\n",
        "# Check shapes of extracted features\n",
        "all_color_histograms.shape, all_edge_histograms.shape\n"
      ],
      "metadata": {
        "id": "hyoRfw8FPzso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to plot histogram\n",
        "def plot_histogram(data, title, xlabel, ylabel, bins=50):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.hist(data.flatten(), bins=bins, color='skyblue', edgecolor='black')\n",
        "    plt.title(title)\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.grid(axis='y', alpha=0.75)\n",
        "    plt.show()\n",
        "\n",
        "# Plot color histogram distribution\n",
        "plot_histogram(all_color_histograms, 'Color Histogram Distribution', 'Pixel Intensity', 'Frequency')\n",
        "\n",
        "# Plot edge histogram distribution\n",
        "plot_histogram(all_edge_histograms, 'Edge Histogram Distribution', 'Edge Intensity', 'Frequency')\n"
      ],
      "metadata": {
        "id": "IlAjk5C3P4EB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize standard scaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Normalize color histogram features\n",
        "all_color_histograms_normalized = scaler.fit_transform(all_color_histograms)\n",
        "\n",
        "# Normalize edge histogram features\n",
        "all_edge_histograms_normalized = scaler.fit_transform(all_edge_histograms)\n",
        "\n",
        "# Check shapes of normalized features\n",
        "all_color_histograms_normalized.shape, all_edge_histograms_normalized.shape\n"
      ],
      "metadata": {
        "id": "KJsx0WRWP6Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Combine color and edge histogram features\n",
        "all_features = np.concatenate((all_color_histograms_normalized, all_edge_histograms_normalized), axis=1)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test = train_test_split(all_features, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check shapes of training and testing sets\n",
        "X_train.shape, X_test.shape\n"
      ],
      "metadata": {
        "id": "fXc73-dAP8io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Means CLustering**"
      ],
      "metadata": {
        "id": "k_DV4p0oQrNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Determine the optimal number of clusters using the silhouette score\n",
        "silhouette_scores = []\n",
        "n_clusters_range = range(2, 11)\n",
        "for n_clusters in n_clusters_range:\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "    labels = kmeans.fit_predict(all_features)\n",
        "    silhouette_avg = silhouette_score(all_features, labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "\n",
        "# Plot silhouette scores\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(n_clusters_range, silhouette_scores, marker='o', linestyle='dashed')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score vs Number of Clusters')\n",
        "plt.grid(axis='both', alpha=0.75)\n",
        "plt.show()\n",
        "\n",
        "# Apply K-Means clustering with the optimal number of clusters\n",
        "optimal_n_clusters = n_clusters_range[np.argmax(silhouette_scores)]\n",
        "kmeans = KMeans(n_clusters=optimal_n_clusters, random_state=42)\n",
        "labels = kmeans.fit_predict(all_features)\n",
        "\n"
      ],
      "metadata": {
        "id": "cG9oz3fxP-Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Anomaly Detection**\n"
      ],
      "metadata": {
        "id": "zyjtzz0YQgaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Normalize the features to be in the range [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "features_normalized = scaler.fit_transform(all_features)\n",
        "\n",
        "# Build the autoencoder model\n",
        "input_layer = Input(shape=(features_normalized.shape[1],))\n",
        "encoded = Dense(64, activation='relu')(input_layer)\n",
        "decoded = Dense(features_normalized.shape[1], activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "autoencoder.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Train the autoencoder\n",
        "autoencoder.fit(features_normalized, features_normalized, epochs=50, batch_size=16, shuffle=True, validation_split=0.2)\n",
        "\n",
        "# Calculate the reconstruction error for each data point\n",
        "reconstructed_features = autoencoder.predict(features_normalized)\n",
        "reconstruction_error = np.mean(np.square(features_normalized - reconstructed_features), axis=1)\n",
        "\n",
        "# Plot the reconstruction error\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(reconstruction_error, bins=50, color='skyblue', edgecolor='black')\n",
        "plt.title('Reconstruction Error Distribution')\n",
        "plt.xlabel('Reconstruction Error')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(axis='y', alpha=0.75)\n",
        "plt.show()\n",
        "\n",
        "# Identify anomalies based on the reconstruction error\n",
        "threshold = np.percentile(reconstruction_error, 95)  # Set the threshold as the 95th percentile of the reconstruction error\n",
        "anomalies = np.where(reconstruction_error > threshold)[0]\n",
        "\n",
        "# Print the indices of the anomalies\n",
        "print(\"Anomalies detected at indices:\", anomalies)\n"
      ],
      "metadata": {
        "id": "D0gtdeMxQU3b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
